# PDFã«outlineã‚’ã¤ã‘ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#
# æ¦‚è¦:
#  PDFãƒ•ã‚¡ã‚¤ãƒ«ã®æœ¬æ–‡ä¸­ã«ã‚ã‚‹ç›®æ¬¡ã®æ–‡å­—åˆ—ã‚’è§£æã—ã€
#  è§£æçµæœã‚’å…ƒã«PDFã«ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‚’è¨­å®šã™ã‚‹
# ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—:
#  pip install pdfminer.six
#  pip install pdfrw
#  pip install reportlab
# å®Ÿè¡Œæ–¹æ³•:
#  python add_outline_to_pdf.py


import io
import re
from pathlib import Path
from pdfminer.converter import TextConverter
from pdfminer.layout import LAParams
from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
from pdfminer.pdfpage import PDFPage
from pdfrw import PdfReader
from pdfrw.buildxobj import pagexobj
from pdfrw.toreportlab import makerl
from reportlab.pdfgen.canvas import Canvas


# è¨­å®šé …ç›®
# å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
input_pdf = "ç—…æ°—ãŒè¦‹ãˆã‚‹_å°å…ç§‘_OCR.pdf"
# å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
output_pdf = "ç—…æ°—ãŒè¦‹ãˆã‚‹_å°å…ç§‘_OCR_ç›®æ¬¡ä»˜ã.pdf"

# ãƒšãƒ¼ã‚¸ç•ªå·ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆèª¿æ•´
page_offset = 21

# ç›®æ¬¡ãŒå«ã¾ã‚Œã‚‹ãƒšãƒ¼ã‚¸ç•ªå· (0å§‹ã¾ã‚Šã§æŒ‡å®š)
index_pages = list(range(12, 20))

# ãƒ¬ãƒ™ãƒ«1ã¨ã—ã¦æ‰±ã†ãƒšãƒ¼ã‚¸ç•ªå·ã®ãƒªã‚¹ãƒˆï¼ˆç›®æ¬¡ãƒšãƒ¼ã‚¸å†…ã®å®Ÿéš›ã®ãƒšãƒ¼ã‚¸ä½ç½®ï¼‰
# ä¾‹: ç›®æ¬¡ã®15ãƒšãƒ¼ã‚¸ç›®ï¼ˆ0-indexedã§14ï¼‰ã«ã‚ã‚‹é …ç›®ã‚’ãƒ¬ãƒ™ãƒ«1ã«ã™ã‚‹å ´åˆ
level1_index_pages = []  # [14, 15, 16] ã®ã‚ˆã†ã«æŒ‡å®š

# æ‰‹å‹•ã§ãƒ¬ãƒ™ãƒ«1ã«æŒ‡å®šã™ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰
manual_level1_keywords = [
    'å°å…ç§‘ç·è«–', 'æ–°ç”Ÿå…', 'å…ˆå¤©ç•°å¸¸', 'æ¶ˆåŒ–å™¨ç–¾æ‚£', 'è…«ç˜', 'å¾ªç’°å™¨ç–¾æ‚£', 
    'ä»£è¬ãƒ»å†…åˆ†æ³Œç–¾æ‚£', 'è…ãƒ»æ³Œå°¿å™¨ãƒ»ç”Ÿæ®–å™¨ç–¾æ‚£', 'å…ç–«ãƒ»ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼ç–¾æ‚£',
    'è† åŸç—…', 'è¡€æ¶²ãƒ»é€ è¡€å™¨ç–¾æ‚£', 'æ„ŸæŸ“ç—‡', 'å‘¼å¸å™¨ç–¾æ‚£', 'ç¥çµŒç–¾æ‚£', 'ç²¾ç¥ç–¾æ‚£', 
    'éª¨ãƒ»é–¢ç¯€ç–¾æ‚£'
]

# OCRèª¤æ¤ã®è£œæ­£è¾æ›¸ï¼ˆåŸºæœ¬çš„ãªã‚‚ã®ï¼‰
ocr_corrections = {
    'ï¾¡': 'è…«',
    'â€¢': 'ãƒ»',
    'Â©': '15',
    'ã€”': '[',
    'ã€•': ']',
    'ï¾±': 'ãƒ³',
    'Wå·is': 'Willis',
    'ï¾Ÿ': 'ã‚œ',
    'ï¾': 'ã‚›',
}

# é™¤å¤–ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
exclude_keywords = [
    'An Illustrated Reference Guide',
    'An lllustrated Reference Guide',
    'column',
    'supplement',
    'Supplement',
]


def correct_ocr_text(text: str) -> str:
    """OCRèª¤æ¤ã‚’è£œæ­£ã™ã‚‹"""
    # åŸºæœ¬çš„ãªè¾æ›¸ã«ã‚ˆã‚‹è£œæ­£
    for wrong, correct in ocr_corrections.items():
        text = text.replace(wrong, correct)
    
    return text


def should_exclude(line: str) -> bool:
    """é™¤å¤–ã™ã¹ãè¡Œã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    line = line.strip()
    for keyword in exclude_keywords:
        if keyword.lower() in line.lower():
            return True
    return False


def detect_level(line: str, title: str, current_page_idx: int) -> int:
    """
    ç›®æ¬¡ã®ãƒ¬ãƒ™ãƒ«ã‚’åˆ¤å®š
    
    Args:
        line: ç›®æ¬¡ã®è¡Œå…¨ä½“
        title: ã‚¿ã‚¤ãƒˆãƒ«éƒ¨åˆ†
        current_page_idx: ç¾åœ¨ã®ç›®æ¬¡ãƒšãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    
    Returns:
        ãƒ¬ãƒ™ãƒ« (1 or 2)
    """
    clean_title = title.strip()
    
    # ãƒ¬ãƒ™ãƒ«1ã®åˆ¤å®š
    # 1. ç« ç•ªå·ãŒã‚ã‚‹
    if re.match(r'^ç¬¬\s*[0-9]+\s*ç« ', line):
        return 1
    
    # 2. æŒ‡å®šã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã«ã‚ã‚‹
    if current_page_idx in level1_index_pages:
        return 1
    
    # 3. æ‰‹å‹•æŒ‡å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ä¸€è‡´
    for keyword in manual_level1_keywords:
        if keyword in clean_title:
            return 1
    
    # ãã‚Œä»¥å¤–ã¯å…¨ã¦ãƒ¬ãƒ™ãƒ«2
    return 2


def get_user_input():
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰å…¥åŠ›ã‚’å–å¾—"""
    print("=" * 60)
    print("PDFç›®æ¬¡è¿½åŠ ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰")
    print("=" * 60)
    print()
    
    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹å…¥åŠ›
    global input_pdf, output_pdf
    use_default = input(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã‹ï¼Ÿ ({input_pdf}) (y/n): ").strip().lower()
    
    if use_default != 'y':
        while True:
            input_pdf = input("PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip().strip('"')
            if Path(input_pdf).exists():
                break
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_pdf}")
        
        input_path = Path(input_pdf)
        output_pdf = str(input_path.parent / f"{input_path.stem}_ç›®æ¬¡ä»˜ã.pdf")
    
    print(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {input_pdf}")
    print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_pdf}")
    print()
    
    # ç›®æ¬¡ãƒšãƒ¼ã‚¸ã®ç¯„å›²
    global index_pages
    use_default_pages = input(f"ç›®æ¬¡ãƒšãƒ¼ã‚¸ç¯„å›²ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ ({index_pages[0]}ã€œ{index_pages[-1]}) ã«ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").strip().lower()
    
    if use_default_pages != 'y':
        while True:
            try:
                index_start = int(input("ç›®æ¬¡ã®é–‹å§‹ãƒšãƒ¼ã‚¸ (0å§‹ã¾ã‚Š): ").strip())
                index_end = int(input("ç›®æ¬¡ã®çµ‚äº†ãƒšãƒ¼ã‚¸ (0å§‹ã¾ã‚Š): ").strip())
                if index_start < index_end:
                    index_pages = list(range(index_start, index_end))
                    break
                print("âŒ é–‹å§‹ãƒšãƒ¼ã‚¸ã¯çµ‚äº†ãƒšãƒ¼ã‚¸ã‚ˆã‚Šå°ã•ã„å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            except ValueError:
                print("âŒ æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    
    # ãƒ¬ãƒ™ãƒ«1ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è¿½åŠ 
    print("\nãƒ¬ãƒ™ãƒ«1ã¨ã—ã¦æ‰±ã„ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¾ã™ã‹ï¼Ÿ")
    print("ç¾åœ¨ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:", ', '.join(manual_level1_keywords[:5]), '...')
    add_keywords = input("è¿½åŠ ã™ã‚‹å ´åˆã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ï¼ˆç©ºç™½ã§ã‚¹ã‚­ãƒƒãƒ—ï¼‰: ").strip()
    
    if add_keywords:
        new_keywords = [k.strip() for k in add_keywords.split(',')]
        manual_level1_keywords.extend(new_keywords)
        print(f"âœ“ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¾ã—ãŸ: {new_keywords}")


def normalize_outline_levels(outlines: list) -> list:
    """ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã®ãƒ¬ãƒ™ãƒ«ã‚’æ­£è¦åŒ–ï¼ˆãƒ¬ãƒ™ãƒ«1ã¨2ã®ã¿ï¼‰"""
    if not outlines:
        return outlines
    
    normalized = []
    current_level = 0
    
    for title, page_num, level in outlines:
        # ãƒ¬ãƒ™ãƒ«ã¯1ã‹2ã®ã¿
        if level < 1:
            level = 1
        elif level > 2:
            level = 2
        
        # ãƒ¬ãƒ™ãƒ«0ã‹ã‚‰ã®é·ç§»ã‚’è€ƒæ…®
        if current_level == 0:
            adjusted_level = level
        elif level > current_level + 1:
            # ãƒ¬ãƒ™ãƒ«0â†’2ã®å ´åˆã¯ãƒ¬ãƒ™ãƒ«1ã‚’æŒŸã‚€
            adjusted_level = current_level + 1
        else:
            adjusted_level = level
        
        normalized.append([title, page_num, adjusted_level])
        current_level = adjusted_level
    
    return normalized


def calculate_page_offset(input_file: str, index_pages: list) -> int:
    """ãƒšãƒ¼ã‚¸ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è‡ªå‹•è¨ˆç®—"""
    print("\nğŸ“Š ãƒšãƒ¼ã‚¸ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è‡ªå‹•è¨ˆç®—ä¸­...")
    
    # æœ€åˆã®ç›®æ¬¡é …ç›®ã‚’å–å¾—
    test_title, test_page = find_first_content_title(input_file, index_pages)
    
    if not test_title or not test_page:
        print("âš ï¸  ç›®æ¬¡ã‹ã‚‰é …ç›®ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
        offset = int(input("ãƒšãƒ¼ã‚¸ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’æ‰‹å‹•ã§å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip())
        return offset
    
    print(f"æ¤œè¨¼ã‚¿ã‚¤ãƒˆãƒ«: {test_title}")
    print(f"ç›®æ¬¡è¨˜è¼‰ãƒšãƒ¼ã‚¸: {test_page}")
    
    # å®Ÿéš›ã®ãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢
    actual_page = find_content_page(input_file, test_title, max(index_pages) + 1)
    
    if actual_page is not None:
        offset = actual_page - test_page + 1
        print(f"âœ“ å®Ÿéš›ã®PDFãƒšãƒ¼ã‚¸: {actual_page + 1}")
        print(f"âœ“ è¨ˆç®—ã•ã‚ŒãŸã‚ªãƒ•ã‚»ãƒƒãƒˆ: {offset}")
        return offset
    else:
        print(f"âš ï¸  '{test_title}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        offset = int(input("ãƒšãƒ¼ã‚¸ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’æ‰‹å‹•ã§å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip())
        return offset


def find_first_content_title(input_file: str, index_pages: list) -> tuple:
    """ç›®æ¬¡ã‹ã‚‰æœ€åˆã®é …ç›®ã‚’è¦‹ã¤ã‘ã‚‹"""
    rsrcmgr = PDFResourceManager()
    
    with open(input_file, "rb") as fp:
        for pidx, page in enumerate(PDFPage.get_pages(fp)):
            if pidx not in index_pages:
                continue
            
            out_fp = io.StringIO()
            device = TextConverter(rsrcmgr, out_fp, laparams=LAParams(), imagewriter=None)
            interpreter = PDFPageInterpreter(rsrcmgr, device)
            interpreter.process_page(page)
            out_fp.seek(0)
            page_str = out_fp.read()
            
            page_str = correct_ocr_text(page_str)
            lines = page_str.split('\n')
            
            for line in lines:
                line = line.strip()
                if should_exclude(line) or not line:
                    continue
                
                match = re.match(r'^(.+?)\s+([0-9]+)\s*$', line)
                if match:
                    title = match.group(1).strip()
                    page_num = match.group(2).strip()
                    
                    title = re.sub(r'[\.ã€‚ã€,\s]+$', '', title)
                    
                    if not re.match(r'^[0-9]+$', title) and len(title) > 2:
                        return title, int(page_num)
    
    return None, None


def find_content_page(input_file: str, target_title: str, start_page: int = 20) -> int:
    """æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ãŒå®Ÿéš›ã«å«ã¾ã‚Œã‚‹ãƒšãƒ¼ã‚¸ã‚’æ¢ã™"""
    rsrcmgr = PDFResourceManager()
    
    with open(input_file, "rb") as fp:
        for pidx, page in enumerate(PDFPage.get_pages(fp)):
            if pidx < start_page:
                continue
            
            out_fp = io.StringIO()
            device = TextConverter(rsrcmgr, out_fp, laparams=LAParams(), imagewriter=None)
            interpreter = PDFPageInterpreter(rsrcmgr, device)
            interpreter.process_page(page)
            out_fp.seek(0)
            page_str = out_fp.read()
            
            if target_title in page_str:
                return pidx
    
    return None


def parse_outline(input_file: str, index_pages: list, page_offset: int):
    """ç›®æ¬¡ã‚’è§£æ"""
    rsrcmgr = PDFResourceManager()
    outlines = []
    
    print("\nğŸ“– ç›®æ¬¡ã®è§£æã‚’é–‹å§‹ã—ã¾ã™...")
    
    with open(input_file, "rb") as fp:
        for pidx, page in enumerate(PDFPage.get_pages(fp)):
            if pidx not in index_pages:
                continue
            
            out_fp = io.StringIO()
            device = TextConverter(rsrcmgr, out_fp, laparams=LAParams(), imagewriter=None)
            interpreter = PDFPageInterpreter(rsrcmgr, device)
            interpreter.process_page(page)
            out_fp.seek(0)
            page_str = out_fp.read()
            
            # OCRèª¤æ¤ã‚’è£œæ­£
            page_str = correct_ocr_text(page_str)
            
            lines = page_str.split('\n')
            for i, line in enumerate(lines):
                line = line.strip()
                
                if not line or should_exclude(line):
                    continue
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ã‚¿ã‚¤ãƒˆãƒ« ãƒšãƒ¼ã‚¸ç•ªå·
                match = re.match(r'^(.+?)\s+([0-9]+)\s*$', line)
                if match:
                    title = match.group(1).strip()
                    page_num = match.group(2).strip()
                    
                    title = re.sub(r'[\.ã€‚ã€,\s]+$', '', title)
                    
                    if not re.match(r'^[0-9]+$', title):
                        level = detect_level(line, title, pidx)
                        try:
                            actual_page = int(page_num) - 1 + page_offset
                            outlines.append([title, actual_page, level])
                            level_mark = "â˜…" if level == 1 else "  "
                            print(f"{level_mark} {title} (ãƒ¬ãƒ™ãƒ«{level})")
                        except ValueError:
                            pass
                    continue
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ï¼ˆæ¬¡è¡Œã«ãƒšãƒ¼ã‚¸ç•ªå·ï¼‰
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    if re.match(r'^[0-9]+\s*$', next_line):
                        title = line
                        page_num = next_line
                        
                        title = re.sub(r'[\.ã€‚ã€,\s]+$', '', title)
                        
                        if not re.match(r'^[0-9]+$', title):
                            level = detect_level(line, title, pidx)
                            try:
                                actual_page = int(page_num) - 1 + page_offset
                                outlines.append([title, actual_page, level])
                                level_mark = "â˜…" if level == 1 else "  "
                                print(f"{level_mark} {title} (ãƒ¬ãƒ™ãƒ«{level})")
                            except ValueError:
                                pass
    
    return outlines


def add_outline(input_file: str, output_file: str, outlines: list):
    """ç›®æ¬¡ã‚’PDFã«è¿½åŠ """
    print("\nğŸ”– ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‚’è¿½åŠ ä¸­...")
    
    outlines = normalize_outline_levels(outlines)
    
    pages = PdfReader(input_file, decompress=False).pages
    out_canvas = Canvas(output_file)
    
    out_canvas.bookmarkPage("toc")
    out_canvas.addOutlineEntry("ç›®æ¬¡", "toc", 0)
    
    added_count = 0
    error_count = 0
    
    for idx, page in enumerate(pages):
        out_page = pagexobj(page)
        out_canvas.setPageSize(tuple(out_page.BBox[2:]))
        out_canvas.doForm(makerl(out_canvas, out_page))
        
        target_outlines = [d for d in outlines if idx == int(d[1])]
        for bookmark_idx, outline_data in enumerate(target_outlines):
            out_bookmark = str(idx) + "p-" + str(bookmark_idx)
            out_canvas.bookmarkPage(out_bookmark)
            
            try:
                out_canvas.addOutlineEntry(outline_data[0], out_bookmark, outline_data[2])
                added_count += 1
            except ValueError as e:
                error_count += 1
                try:
                    out_canvas.addOutlineEntry(outline_data[0], out_bookmark, 2)
                    added_count += 1
                except:
                    pass
        
        out_canvas.showPage()
    
    out_canvas.showOutline()
    out_canvas.save()
    
    print(f"\nâœ… å®Œäº†ï¼")
    print(f"   è¿½åŠ æˆåŠŸ: {added_count}å€‹")
    if error_count > 0:
        print(f"   ã‚¨ãƒ©ãƒ¼: {error_count}å€‹ï¼ˆä¸€éƒ¨ã¯è‡ªå‹•ä¿®æ­£ï¼‰")


if __name__ == '__main__':
    try:
        print("=" * 60)
        print("PDFç›®æ¬¡è¿½åŠ ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰")
        print("=" * 60)
        print()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
        get_user_input()
        
        print("\n" + "=" * 60)
        print("å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
        print("=" * 60)
        
        # ãƒšãƒ¼ã‚¸ã‚ªãƒ•ã‚»ãƒƒãƒˆã®è¨ˆç®—
        auto_offset = input("\nãƒšãƒ¼ã‚¸ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è‡ªå‹•è¨ˆç®—ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").strip().lower()
        if auto_offset == 'y':
            page_offset = calculate_page_offset(input_pdf, index_pages)
        
        print(f"\nä½¿ç”¨ã™ã‚‹ãƒšãƒ¼ã‚¸ã‚ªãƒ•ã‚»ãƒƒãƒˆ: {page_offset}")
        
        # ç›®æ¬¡ã‚’è§£æ
        outline_list = parse_outline(input_pdf, index_pages, page_offset)
        print(f"\nåˆè¨ˆ {len(outline_list)} å€‹ã®ç›®æ¬¡é …ç›®ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        
        if len(outline_list) == 0:
            print("âŒ ç›®æ¬¡é …ç›®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            exit(1)
        
        # PDFã«ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‚’è¿½åŠ 
        add_outline(input_pdf, output_pdf, outline_list)
        print(f"\nğŸ“„ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_pdf}")
        
    except KeyboardInterrupt:
        print("\n\nå‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
        exit(0)
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        import traceback
        traceback.print_exc()
        exit(1)
